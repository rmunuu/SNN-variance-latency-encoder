{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345089/1275851596.py:3: DeprecationWarning: The module snntorch.backprop will be deprecated in  a future release. Writing out your own training loop will lead to substantially faster performance.\n",
      "  from snntorch import backprop\n"
     ]
    }
   ],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from encoder_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RLencoder(torch.nn.Module):\n",
    "#     def __init__(self, time_window, fire_window_ratio):\n",
    "#         super(RLencoder, self).__init__()\n",
    "#         self.time_window = time_window\n",
    "#         self.fire_window = int(time_window * fire_window_ratio)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, _, height, width = x.shape\n",
    "#         spikes = torch.zeros(batch_size, height, width, self.time_window).to(x.device)\n",
    "        \n",
    "#         var = variance_map(x, 5)\n",
    "#         latency = calculate_latency(var, self.time_window, self.fire_window, mode='log')\n",
    "        \n",
    "#         spike_prob = torch.rand(batch_size, height, width, self.time_window).to(x.device)\n",
    "\n",
    "#         time_range = torch.arange(self.time_window).view(1, 1, 1, -1).to(x.device)\n",
    "#         firing_mask = ((time_range >= latency.unsqueeze(-1)) & (time_range < (latency + self.fire_window).unsqueeze(-1))).squeeze().float()\n",
    "\n",
    "#         spikes = (spike_prob < x.squeeze().unsqueeze(-1)) * firing_mask\n",
    "#         # print(spikes.shape)\n",
    "\n",
    "#         # print(\"spikes shape\", spikes.shape)\n",
    "#         # print(\"spike_prob shape\", spike_prob.shape)\n",
    "#         # print(\"x shape\", x.shape)\n",
    "#         # print(\"firing_mask shape\", firing_mask.shape)\n",
    "#         # print(\"time_range shape\", time_range.shape)\n",
    "\n",
    "#         return spikes\n",
    "\n",
    "# def variance_map(image, kernel_size):\n",
    "#     pad_size = kernel_size // 2\n",
    "#     padded_image = F.pad(image, pad=(pad_size, pad_size, pad_size, pad_size), mode='reflect')\n",
    "    \n",
    "#     local_mean = F.avg_pool2d(padded_image, kernel_size, stride=1, padding=0)\n",
    "#     squared_image = padded_image ** 2\n",
    "#     local_mean_squared = F.avg_pool2d(squared_image, kernel_size, stride=1, padding=0)\n",
    "    \n",
    "#     variance = local_mean_squared - local_mean ** 2\n",
    "#     return variance\n",
    "\n",
    "# def calculate_latency(div_image, time_window, fire_window, mode='linear'):\n",
    "#     min_div, max_div = div_image.min(), div_image.max()\n",
    "#     normalized_div = (div_image - min_div) / (max_div - min_div)\n",
    "#     if mode == \"linear\":\n",
    "#         latency = (time_window - fire_window) * (1 - normalized_div)\n",
    "#     elif mode == \"log\":\n",
    "#         latency = 1 / (normalized_div + 1 / (time_window - fire_window))\n",
    "    \n",
    "#     return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader arguments\n",
    "batch_size = 128\n",
    "data_path='/tmp/data/MNIST'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345089/4292142752.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/home/rmunuu/miniconda3/envs/ai/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 25\n",
    "\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(num_inputs, num_hidden),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Linear(num_hidden, num_outputs),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "\n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in train_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "\n",
    "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SF.ce_rate_loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_window:  100\n",
      "fire_window:  20\n"
     ]
    }
   ],
   "source": [
    "time_window = 100\n",
    "fire_window_ratio = 0.2\n",
    "\n",
    "encoder = RLencoder(time_window, fire_window_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, num_steps, data):\n",
    "  mem_rec = []\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  spike_trains = encoder(data)\n",
    "  spike_trains = spike_trains.permute(3, 0, 1, 2)\n",
    "\n",
    "  for step in range(num_steps):\n",
    "      spk_out, mem_out = net(spike_trains[step].view(batch_size, -1))\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "\n",
    "  return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RLencoder(torch.nn.Module):\n",
    "#     def __init__(self, time_window, fire_window_ratio):\n",
    "#         super(RLencoder, self).__init__()\n",
    "#         self.time_window = time_window\n",
    "#         self.fire_window = int(time_window * fire_window_ratio)\n",
    "#         print(\"time_window: \", self.time_window)\n",
    "#         print(\"fire_window: \", self.fire_window)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, _, height, width = x.shape\n",
    "#         spikes = torch.zeros(batch_size, height, width, self.time_window).to(x.device)\n",
    "\n",
    "#         # gray = to_grayscale(x)\n",
    "#         # max_latency = 100\n",
    "#         var = variance_map(x, 5)\n",
    "#         latency = calculate_latency(var, self.time_window, self.fire_window, mode='log')\n",
    "\n",
    "#         spike_prob = torch.rand(batch_size, height, width).to(x.device)\n",
    "\n",
    "#         for t in range(self.time_window):\n",
    "#             firing_mask = ((t >= latency) & (t < latency + self.fire_window)).float().squeeze(1)\n",
    "#             # print(\"spikes shape\", spikes.shape)\n",
    "#             # print(\"spike_prob shape\", spike_prob.shape)\n",
    "#             # print(\"x.squeeze shape\", x.squeeze(1).shape)\n",
    "#             # print(\"firing_mask shape\", firing_mask.shape)\n",
    "#             spikes[:, :, :, t] = (spike_prob < x.squeeze(1)) * firing_mask\n",
    "\n",
    "#         return spikes\n",
    "\n",
    "# # def to_grayscale(image):\n",
    "# #     return torch.mean(image, dim=1, keepdim=True)\n",
    "\n",
    "# def variance_map(image, kernel_size):\n",
    "#     # kernel_size : odd\n",
    "    \n",
    "#     pad_size = kernel_size // 2\n",
    "#     padded_image = F.pad(image, pad=(pad_size, pad_size, pad_size, pad_size), mode='reflect')\n",
    "    \n",
    "#     local_mean = F.avg_pool2d(padded_image, kernel_size, stride=1, padding=0)\n",
    "    \n",
    "#     squared_image = padded_image ** 2\n",
    "#     local_mean_squared = F.avg_pool2d(squared_image, kernel_size, stride=1, padding=0)\n",
    "    \n",
    "#     variance = local_mean_squared - local_mean ** 2\n",
    "#     # variance = torch.mean(variance, dim=1, keepdim=True)\n",
    "    \n",
    "#     return variance\n",
    "\n",
    "# def calculate_latency(div_image, time_window, fire_window, mode='linear'):\n",
    "#     min_div, max_div = div_image.min(), div_image.max()\n",
    "#     normalized_div = (div_image - min_div) / (max_div - min_div)\n",
    "#     if mode == \"linear\":\n",
    "#         latency = (time_window - fire_window) * (1 - normalized_div)\n",
    "#         return latency\n",
    "#     elif mode == \"log\":\n",
    "#         latency = 1/(normalized_div + 1/(time_window - fire_window))\n",
    "#         return latency\n",
    "\n",
    "# def plot_raster(spike_trains, num_neurons):\n",
    "#     spike_trains = spike_trains.cpu().numpy()\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "    \n",
    "#     for neuron_idx in range(num_neurons):\n",
    "#         neuron_spikes = spike_trains[0, neuron_idx // 28, neuron_idx % 28]\n",
    "#         spike_times = neuron_spikes.nonzero()[0]\n",
    "#         plt.vlines(spike_times, neuron_idx + 0.5, neuron_idx + 1.5)\n",
    "    \n",
    "#     plt.axis([0, 100, 0, 784])\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Neuron Index')\n",
    "#     plt.title('Raster Plot of Spikes')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345089/1338605826.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/rmunuu/miniconda3/envs/ai/lib/python3.12/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Test Acc: 9.80%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# spk_rec, _ = forward_pass(net, num_steps, data)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# loss_val = loss_fn(spk_rec, targets)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m---> 20\u001b[0m     spk_rec, _ \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m loss_fn(spk_rec, targets)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# loss_val.backward()\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(net, num_steps, data)\u001b[0m\n\u001b[1;32m      7\u001b[0m spike_trains \u001b[38;5;241m=\u001b[39m spike_trains\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 10\u001b[0m     spk_out, mem_out \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_trains\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     spk_rec\u001b[38;5;241m.\u001b[39mappend(spk_out)\n\u001b[1;32m     12\u001b[0m     mem_rec\u001b[38;5;241m.\u001b[39mappend(mem_out)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/snntorch/_neurons/leaky.py:209\u001b[0m, in \u001b[0;36mLeaky.forward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m input_\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(input_, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_function(input_)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_quant:\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/snntorch/_neurons/neurons.py:106\u001b[0m, in \u001b[0;36mSpikingNeuron.mem_reset\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates detached reset signal if mem > threshold.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mReturns reset.\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m mem_shift \u001b[38;5;241m=\u001b[39m mem \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\n\u001b[0;32m--> 106\u001b[0m reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspike_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmem_shift\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reset\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/snntorch/surrogate.py:151\u001b[0m, in \u001b[0;36mfast_sigmoid.<locals>.inner\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(x):\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastSigmoid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.12/site-packages/snntorch/surrogate.py:135\u001b[0m, in \u001b[0;36mFastSigmoid.forward\u001b[0;34m(ctx, input_, slope)\u001b[0m\n\u001b[1;32m    133\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(input_)\n\u001b[1;32m    134\u001b[0m ctx\u001b[38;5;241m.\u001b[39mslope \u001b[38;5;241m=\u001b[39m slope\n\u001b[0;32m--> 135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "num_steps = time_window\n",
    "loss_hist = []\n",
    "test_acc_hist = []\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        # spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "        # loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        with autocast():\n",
    "            spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "            loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # loss_val.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss_val).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        if counter % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "\n",
    "                test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "                print(f\"Iteration {counter}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
    "                test_acc_hist.append(test_acc.item())\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(facecolor=\"w\")\n",
    "plt.plot(test_acc_hist)\n",
    "plt.title(\"Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_test(net, num_steps, data):\n",
    "  mem_rec = []\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(num_steps):\n",
    "      spk_out, mem_out = net(data.view(data.size(0), -1))\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "\n",
    "  return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "  net.eval()\n",
    "  for data, targets in test_loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    test_spk, _ = forward_pass_test(net, num_steps, data)\n",
    "\n",
    "    # calculate total accuracy\n",
    "    _, predicted = test_spk.sum(dim=0).max(1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correctly classified test set images: 9300/10000\n",
      "Test Set Accuracy: 93.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
    "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
